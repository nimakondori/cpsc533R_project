train: 
  seed: 200
  batch_size: 40
  num_epochs: 200  
  num_workers: 0
  use_wandb: True
  wandb_project_name: MultiTasking_Transformer
  wandb_entity: rcl_stroke
  wandb_mode: online
  wandb_run_name: "debug_run"

  lr_schedule: 
    name: "reduce_lr_on_plateau"
    mode: 'min'
    factor: 0.5  # Factor by which the learning rate will be reduced
    patience: 2 # Number of epochs with no improvement after which learning rate will be reduced
    threshold: 0.01  # Threshold for measuring the new optimum, to only focus on significant changes
    min_lr: 0.000001  # 1e-6
    verbose: True

  optimizer: 
    name: adam
    lr: 0.001  # 1e-3
    weight_decay: 0.0001  # 1e-4

  criterion:
    mae:
      loss_weight: 1 # Coefficient in weighted loss calculation    

model:
  name: vit
  # checkpoint_path: "/workspace/cpsc533R_project/saved_files/debug_run/checkpoint_0_16.pth"
  checkpoint_path: ""
  image_size: 224
  n_channels: 1
  patch_size: 7
  n_classes: 8
  d_model: 256
  n_layers: 6
  n_heads: 8
  d_mlp: 512
  d_head: 32
  pool: 'cls'
  dropout: 0.1
  emb_dropout: 0.1

eval:  
  standards: ["mse", "landmarkcoorderror"]  
  standard: "mse"  
  minimize: True

data: 
  - dataset:
      name: lvidlandmark
      data_dir: '/arc/project/st-puranga-1/datasets/landmark/Cleaned_LVPLAX2/'
      metadata_dir: '/arc/project/st-puranga-1/datasets/landmark/lv_plax2_cleaned_info_landmark_gt_filtered_es_cleaned.csv'
      transform: 
        image_size: 224
        crop_sizd: 28
